---
title: "SZ - Commenting Systems in Archive Daten"
output: 
    html_document: 
      toc: TRUE
      code_folding: "hide"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(urltools)
library(MetBrewer)
library(ggtext)

source("../shiny/config/config-graphic.R")

load(file = "../data/df_snippet_info.RData")
load(file = "../data/German/df_sites_per_year.RData")

df_timespan_year <- seq(ymd("2007-01-01"), ymd("2021-06-01"), by = "year") %>% as_tibble()

year_breaks_for_plotting <- df_timespan_year %>% 
  mutate(years = year(value)) %>% 
  select(years) %>% pull(.)

```


Via Shiny-App ist zu sehen, dass für die SZ lediglich Disqus als Kommentarsystem gefunden wurde. Ein Blick in die Daten sagt, es handelt sich auch nur um ein Snippet, nämlich `disqus-thread`, keine javascript-Einbindung wie bei vielen anderen Seiten. 


### Wann haben wir was gefunden?

Das ist nur die Wiederholung der Daten aus der shiny-app, aber der Ausgangspunkt für einen schnellen Blick in die Daten.

```{r fig.height=2, fig.width=12, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}

# df <- 
  
df_snippit_info %>% 
  filter(site == "sueddeutsche", detected == 1) %>% 
  mutate(year = year(crawl_date)) %>% 
  group_by(site, year) %>% 
  summarise(counted_snippets = n()) %>% 
  ungroup() %>% 
  ggplot(., aes(x = year, y = site, fill = counted_snippets)) +
  geom_tile() +
  scale_fill_gradientn(colors = met.brewer("Hokusai2", type="continuous"), na.value = "grey90", name = "number of detected systems" ) +
  scale_x_continuous(breaks = year_breaks_for_plotting, labels = year_breaks_for_plotting, limits = c(min(year_breaks_for_plotting), max(year_breaks_for_plotting)), expand = c(0,NA)) +
  theme_b03_base + theme_b03_heatmap + theme_b03_facets +
  guides(fill = guide_colorbar(title.position = "top", barwidth = unit(20, "lines"), barheight = unit(.5, "lines")))

```


```{r echo=FALSE, warning=FALSE, error=FALSE}

df_sz_sites_snippets <- df_snippit_info %>% 
  filter(site == "sueddeutsche", detected == 1)

df_sz_sites_crawled <- df_sites_per_year %>% 
  filter(site == "sueddeutsche")

```


### Wie viele Seiten enthalten das Kommentarsystem?

Insgesamt wurden in `r df_sz_sites_snippets %>% nrow` Seiten Disqus entdeckt. Von insgesamt `r df_sz_sites_crawled %>% summarise(sum_sites = sum(counted_sites, na.rm = TRUE)) %>% select(sum_sites) %>% pull(.)` vom Internet Archive zur Verfügung gestellten Seiten.


### Welche Seiten sind das?

Für einen besseren Einblick in die Daten, sind in dieser Tabelle die Links alles Seiten mit Disqus-Snippets mit ihrer Webarchive-URL gelistet. So ist es möglich einzelne Seiten noch einmal anzuschauen.

```{r, echo=FALSE, warning=FALSE, error=FALSE}
DT::datatable(df_sz_sites_snippets %>% 
                mutate(archive_url = paste0("http://web.archive.org/web/", crawl_date, "/", url)) %>% 
                select(crawl_date, archive_url)) #%>% 
```


### In welchen Ressorts wurden Kommentare erlaubt?

Das ist inhaltlich eine eher unerhebliche Frage für jetzt, kann aber helfen um zu verstehen, aus welchen Winkel auf die Daten geschaut werden kann. Hier zeigt sich: die SZ scheint einen Schwerpunkt auf politische Diskussionen zu legen. Suchen wir weiter nach bisher übersehenen Systemen, kann es helfen die Datenmenge zunächst auf das Politik-Ressort zu verengen: Daten werden handelbarer und die Wahrscheinlich höher eventuell etwas zu finden. 

```{r echo=FALSE, error=FALSE, fig.height=4, fig.width=12, warning=FALSE}

df_sz_sites_snippets %>% 
  mutate(section = str_extract(url, "/\\w{1,}/") %>% str_remove_all(., "/")) %>% 
  select(crawl_date, section, url) %>% 
  group_by(section) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  ggplot(., aes(x = count, y = reorder(section, count))) +
  geom_bar(stat = "identity") +
  theme_b03_base

```



### Aus welchen Jahren haben wir überhaupt Daten für die SZ?

Auch das eine Wiederholung der Darstellung aus der shiny-app, zur Einordnung hier noch einmal dargestellt.

```{r error=FALSE, fig.height=4, fig.width=12, warning=FALSE, , echo=FALSE}

df_sz_sites_crawled %>% 
  # filter(site == "sueddeutsche") %>% #View()
  ggplot(., aes(x = year, y = counted_sites)) +
  geom_bar(stat = "identity") +
  scale_x_continuous(breaks = year_breaks_for_plotting, labels = year_breaks_for_plotting, limits = c(min(year_breaks_for_plotting), NA), expand = c(0,NA)) +theme_b03_base
  


```

### Wie passend ist das archive sample für die SZ-Daten

Ich wollte diese Tabelle sehen, weil ich über die Tabelle gescrollt bin, die alle urls aus dem Internet Archive enthält und für mein Gefühl zu oft "quiz" oder "projekte" gelesen habe. Von diesen Subdomains weiß ich ziemlich sicher, dass es dort keine Kommentarfunktion gab. Meine Befürchtung war, dass es zwar viele Daten für die Domain `sueddeutsche.de` gibt, aber zu viele crawls auf subdomains gingen, die für unseren Suchansatz ergebnislos verlaufen müssen.

Diese kleine Tabelle hier zeigt aber, dass es hier keine Unausgewogenheit gibt. Die enthaltenen Subdomains kommen nur in sehr geringen Zahlen vor.

In der Tabelle wird `www` als subdomain gelistet. Alle Seiten mit dieser "Subdomain" sind solche Seiten, die prinzipiell interessant sein können.

```{r, echo=FALSE, warning=FALSE, error=FALSE}

DT::datatable(df_snippit_info %>% 
  filter(site == "sueddeutsche") %>% 
  select(crawl_date, url) %>% 
  distinct() %>% 
  mutate(subdomain = domain(url) %>% suffix_extract(.) %>% select(subdomain) %>% pull(.) ) %>% #View()
  group_by(subdomain) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)))

```

### Kommentarsysteme vor 2015? -oh ja!

Für die unten stehende Tabelle habe ich die Daten gefiltert. Bedingung ist, dass der Artikel im Jahr 2014 gecrawlt wurde, die subdomain "www" hat und in der Politik veröffentlicht wurde (weil oben die häufigsten Diskussionsforen in der Politik angeboten wurden).

In [dieser Seite](http://web.archive.org/web/20140402014702/http://www.sueddeutsche.de/politik/schaeubles-hitlervergleich-weniger-meinen-klueger-reden-1.1926486) sieht man unten ein Formularfeld und auch die Option den Kommentar auf facebook zu posten. Wo tauchte der dann auf? Unter dem Artikelpost bei der SZ oder auf der eigenen facebook-Seite?

Ist es interessant diese Variante von Kommentierung mit in die Snippetsuche aufzunehmen?

```{r, echo=FALSE, warning=FALSE, error=FALSE}

DT::datatable(df_snippit_info %>% 
  filter(site == "sueddeutsche") %>% 
  select(crawl_date, url, sha1) %>% 
  distinct() %>% 
  mutate(subdomain = domain(url) %>% suffix_extract(.) %>% select(subdomain) %>% pull(.),
         year = year(crawl_date),
         section = str_extract(url, "/\\w{1,}/") %>% str_remove_all(., "/"),
         archive_url = paste0("http://web.archive.org/web/", crawl_date, "/", url)) %>% #View()
  filter(year == 2014, subdomain == "www", section == "politik")) #%>% 
  # select(-url, -sha1, -subdomain,-year, -section))
 

```

